[{"path":"/articles/E1_DF_Mixed.html","id":"load-libraries","dir":"Articles","previous_headings":"","what":"Load libraries","title":"E1_DF_Mixed","text":"","code":"library(pacman) library(dplyr) library(tidyverse) library(jsonlite) library(xtable) library(data.table)"},{"path":"/articles/E1_DF_Mixed.html","id":"import-data","dir":"Articles","previous_headings":"","what":"Import Data","title":"E1_DF_Mixed","text":"","code":"# Read the text file from JATOS ... read_file('data/E1/jatos_results_20220330235250.txt') %>%   # ... split it into lines ...   str_split('\\n') %>% first() %>%   # ... filter empty rows ...   discard(function(x) x == '') %>%   # ... parse JSON into a data.frame   map_dfr(fromJSON, flatten=T) -> all_data"},{"path":"/articles/E1_DF_Mixed.html","id":"demographics","dir":"Articles","previous_headings":"","what":"Demographics","title":"E1_DF_Mixed","text":"total 47 participants recruited Amazon’s Mechanical Turk. Mean age 34.9 (range = 22 60 ). 23 females, 24 males. 41 right-handed participants, NA left handed participants. 37 participants reported normal vision, 10 participants reported corrected--normal vision. 37 participants reported English first language, 10 participants reported English second language.","code":"library(tidyr)  demographics <- all_data %>%   filter(trial_type == \"survey-html-form\") %>%   select(ID,response) %>%   unnest_wider(response) %>%   mutate(age = as.numeric(age))  age_demographics <- demographics %>%   summarize(mean_age = mean(age),             sd_age = sd(age),             min_age = min(age),             max_age = max(age))  factor_demographics <- apply(demographics[-1], 2, table)"},{"path":"/articles/E1_DF_Mixed.html","id":"pre-processing","dir":"Articles","previous_headings":"","what":"Pre-processing","title":"E1_DF_Mixed","text":"interested including participants attempted perform task best ability. adopted following exclusion criteria. Lower 75% correct encoding task. means participants failed correctly press F R keys trial.  25% Null responses (120*.25 = 30) test. NULL responses mean participant respond test trial 10 seconds.  Higher 75% response bias recognition task. suggests participants simply pressing button trials.  Making responses fast recognition memory test, indicating weren’t performing task. excluded participants whose mean RT less 300 ms.  Subjects included perform better 55% correct novel lures.","code":"# select data from the study phase study_accuracy <- all_data %>%   filter(experiment_phase == \"study\",          is.na(correct) == FALSE) %>%   group_by(ID)%>%   summarize(mean_correct = mean(correct))  study_excluded_subjects <- study_accuracy %>%   filter(mean_correct < .75) %>%   pull(ID)  ggplot(study_accuracy, aes(x=mean_correct))+   coord_cartesian(xlim=c(0,1))+   geom_vline(xintercept=.75)+   geom_histogram()+   ggtitle(\"Histogram of mean correct responses \\n for each subject during study phase\") # select data from the study phase test_null <- all_data %>%   filter(experiment_phase == \"test\",          response ==\"NULL\") %>%   group_by(ID) %>%   count()  test_null_excluded <- test_null %>%   filter(n > (120*.25)) %>%   pull(ID)  ggplot(test_null, aes(x=n))+   geom_vline(xintercept=30)+   geom_histogram()+   ggtitle(\"Histogram of count of null responses \\n for each subject during test\") test_response_bias <- all_data %>%   filter(experiment_phase == \"test\",          response !=\"NULL\") %>%   mutate(response = as.numeric(response)) %>%   group_by(ID, response) %>%   count() %>%   pivot_wider(names_from = response,               values_from = n,               values_fill = 0) %>%   mutate(bias = abs(`0` - `1`)/120)  test_response_bias_excluded <- test_response_bias %>%   filter(bias > .75) %>%   pull(ID)  ggplot(test_response_bias, aes(x=bias))+   geom_vline(xintercept=.75)+   geom_histogram()+   ggtitle(\"Histogram of response bias \\n for each subject during test phase\") test_mean_rt <- all_data %>%   filter(experiment_phase == \"test\",          response !=\"NULL\",          rt != \"NULL\") %>%   mutate(rt = as.numeric(rt)) %>%   group_by(ID) %>%   summarize(mean_RT = mean(rt))  test_mean_rt_excluded <- test_mean_rt %>%   filter(mean_RT < 300) %>%   pull(ID)  ggplot(test_mean_rt, aes(x=mean_RT))+   geom_vline(xintercept=300)+   geom_histogram()+   ggtitle(\"Histogram of response bias \\n for each subject during test phase\") test_mean_novel_accuracy <- all_data %>%   filter(experiment_phase == \"test\",          test_condition == \"novel\") %>%   mutate(correct = as.logical(correct)) %>%   group_by(ID) %>%   summarize(mean_correct = mean(correct))  test_mean_novel_accuracy_excluded <- test_mean_novel_accuracy %>%   filter(mean_correct < .55) %>%   pull(ID)  ggplot(test_mean_novel_accuracy, aes(x=mean_correct))+   geom_vline(xintercept=.55)+   geom_histogram()+   ggtitle(\"Histogram of mean accuracy for novel lures \\n for each subject during test phase\")"},{"path":"/articles/E1_DF_Mixed.html","id":"all-exclusions","dir":"Articles","previous_headings":"","what":"All exclusions","title":"E1_DF_Mixed","text":"participants recruited online completed experiment web browser. experiment script requests participants attempt task best ability. Nevertheless, possible participants complete experiment submit data without attempting complete task directed. developed set criteria exclude participants whose performance indicated attempting task instructed. criteria also allowed us confirm participants included analysis attempt task instructed best ability. adopted following five criteria: First, encoding phase participants responded instructional cue (remember forget picture trial) pressing “R” “F” keyboard. task demand served attentional check. excluded participants scored lower 75% correct instructional cue identification responses. Second, participants respond 25% trials recognition test excluded. Third, measured response bias (choosing left right picture) recognition test, excluded participants made 75% responses one side (indicating repeatedly pressing button trial). Fourth, excluded participants whose mean reaction time recognition test less 300ms, indicating pressing buttons fast possible without making recognition decision. Finally, computed mean accuracy novel lure condition participants, excluded participants whose mean accuracy less 55% items. together 13 participants excluded.","code":"all_excluded <- unique(c(study_excluded_subjects,                   test_null_excluded,                   test_response_bias_excluded,                   test_mean_rt_excluded,                   test_mean_novel_accuracy_excluded))  length(all_excluded) ## [1] 13"},{"path":[]},{"path":"/articles/E1_DF_Mixed.html","id":"define-helper-functions","dir":"Articles","previous_headings":"","what":"Define Helper functions","title":"E1_DF_Mixed","text":", consider moving functions R package project","code":"# attempt general solution  ## Declare helper functions  ################ # get_mean_sem # data = a data frame # grouping_vars = a character vector of factors for analysis contained in data # dv = a string indicated the dependent variable colunmn name in data # returns data frame with grouping variables, and mean_{dv}, sem_{dv} # note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv  get_mean_sem <- function(data, grouping_vars, dv, digits=3){   a <- data %>%     group_by_at(grouping_vars) %>%     summarize(\"mean_{ dv }\" := round(mean(.data[[dv]]), digits),               \"sem_{ dv }\" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),               .groups=\"drop\")   return(a) }  ################ # get_effect_names # grouping_vars = a character vector of factors for analysis # returns a named list # list contains all main effects and interaction terms # useful for iterating the computation means across design effects and interactions  get_effect_names <- function(grouping_vars){   effect_names <- grouping_vars   if( length(grouping_vars > 1) ){     for( i in 2:length(grouping_vars) ){       effect_names <- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=\":\"))     }   }   effects <- strsplit(effect_names, split=\":\")   names(effects) <- effect_names   return(effects) }  ################ # print_list_of_tables # table_list = a list of named tables # each table is printed  # names are header level 3  print_list_of_tables <- function(table_list){   for(i in 1:length(table_list)){     cat(\"###\",names(table_list[i]))     cat(\"\\n\")     print(knitr::kable(table_list[[i]]))     cat(\"\\n\")   } }"},{"path":"/articles/E1_DF_Mixed.html","id":"conduct-analysis","dir":"Articles","previous_headings":"","what":"Conduct Analysis","title":"E1_DF_Mixed","text":"","code":"# create list to hold results Accuracy <- list()  # Pre-process data for analysis # assign to \"filtered_data\" object Accuracy$filtered_data <- all_data %>%   filter(experiment_phase == \"test\",           ID %in% all_excluded == FALSE)  # declare factors, IVS, subject variable, and DV Accuracy$factors$IVs <- c(\"encoding_stimulus_time\",                           \"encoding_instruction\",                           \"test_condition\") Accuracy$factors$subject <- \"ID\" Accuracy$factors$DV <- \"correct\"  ## Subject-level means used for ANOVA # get individual subject means for each condition Accuracy$subject_means <- get_mean_sem(data=Accuracy$filtered_data,                                        grouping_vars = c(Accuracy$factors$subject,                                                          Accuracy$factors$IVs),                                        dv = Accuracy$factors$DV) ## Condition-level means # get all possible main effects and interactions Accuracy$effects <- get_effect_names(Accuracy$factors$IVs)  Accuracy$means <- lapply(Accuracy$effects, FUN = function(x) {   get_mean_sem(data=Accuracy$filtered_data,              grouping_vars = x,              dv = Accuracy$factors$DV) })  ## ANOVA  # ensure factors are factor class Accuracy$subject_means <- Accuracy$subject_means %>%   mutate_at(Accuracy$factors$IVs,factor) %>%   mutate_at(Accuracy$factors$subject,factor)  # run ANOVA Accuracy$aov.out <- aov(mean_correct ~ encoding_stimulus_time*encoding_instruction*test_condition + Error(ID/(encoding_stimulus_time*encoding_instruction*test_condition)), Accuracy$subject_means)  # save printable summaries Accuracy$apa_print <- papaja::apa_print(Accuracy$aov.out)"},{"path":"/articles/E1_DF_Mixed.html","id":"graphs","dir":"Articles","previous_headings":"","what":"Graphs","title":"E1_DF_Mixed","text":"","code":"Accuracy$graphs$figure <- ggplot(Accuracy$means$`encoding_stimulus_time:encoding_instruction:test_condition`,                                   aes(x=test_condition,                                      y=mean_correct,                                      group=encoding_instruction,                                      fill=encoding_instruction))+   geom_bar(stat=\"identity\", position=\"dodge\")+   geom_errorbar(aes(ymin = mean_correct-sem_correct,                     ymax = mean_correct+sem_correct),                 width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+   facet_wrap(~encoding_stimulus_time)+   coord_cartesian(ylim=c(.4,1))+   geom_hline(yintercept=.5)+   scale_y_continuous(breaks = seq(0.4,1,.1))+   theme_classic(base_size=12)+   ylab(\"Proportion Correct\")+   xlab(\"Lure Type\")+   scale_fill_discrete(name = \" Encoding \\n Instruction\") +   ggtitle(\"E1: Proportion Correct by Stimulus Encoding Duration, \\n Encoding Instruction, and Lure Type\")  Accuracy$graphs$figure"},{"path":"/articles/E1_DF_Mixed.html","id":"print-anova","dir":"Articles","previous_headings":"","what":"Print ANOVA","title":"E1_DF_Mixed","text":"","code":"knitr::kable(xtable(summary(Accuracy$aov.out)))"},{"path":"/articles/E1_DF_Mixed.html","id":"print-means","dir":"Articles","previous_headings":"","what":"Print Means","title":"E1_DF_Mixed","text":"","code":"print_list_of_tables(Accuracy$means)"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/articles/E1_DF_Mixed.html","id":"comparisons","dir":"Articles","previous_headings":"","what":"Comparisons","title":"E1_DF_Mixed","text":"","code":"## Encoding time x instruction Accuracy$simple$DF_500 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_correct) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$DF_1000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_correct) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$DF_2000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_correct) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  # encoding time x test condition  Accuracy$simple$test_500 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,test_condition) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_correct) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$test_1000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_correct) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$test_2000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_correct) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()"},{"path":"/articles/E1_DF_Mixed.html","id":"write-up","dir":"Articles","previous_headings":"","what":"Write-up","title":"E1_DF_Mixed","text":"Proportion correct subject condition submitted 3 (Encoding Duration: 500ms, 1000ms, 2000ms) x 2 (Encoding Instruction: Forget vs. Remember) x 2 (Lure type: Novel vs. Exemplar) fully repeated measures ANOVA. completeness, main effect higher-order interaction described turn. main effect encoding duration significant, \\(F(2, 66) = 2.62\\), \\(p = .080\\), \\(\\hat{\\eta}^2_G = .007\\), 90% CI \\([.000, .048]\\). Proportion correct similar across 500 ms (M = 0.668, SEM = 0.013), 1000 ms (M = 0.7, SEM = 0.012), 2000 ms (M = 0.699, SEM = 0.012) stimulus durations. main effect encoding instruction significant, \\(F(1, 33) = 1.95\\), \\(p = .171\\), \\(\\hat{\\eta}^2_G = .002\\), 90% CI \\([.000, .005]\\). Proportion correct similar remember cues (M = 0.681, SEM = 0.01) forget cues (M = 0.698, SEM = 0.01). main effect lure type significant, \\(F(1, 33) = 133.34\\), \\(p < .001\\), \\(\\hat{\\eta}^2_G = .257\\), 90% CI \\([.070, .444]\\). Proportion correct higher novel lures (M = 0.79, SEM = 0.009) exemplar lures (M = 0.588, SEM = 0.011). main question interest whether directing forgetting vary across encoding duration times. interaction encoding instruction encoding duration , \\(F(2, 66) = 0.95\\), \\(p = .393\\), \\(\\hat{\\eta}^2_G = .003\\), 90% CI \\([.000, .024]\\). Paired sample t-tests used assess directed forgetting effect encoding duration. directed forgetting effect taken difference proportion correct remember minus forget items. 500 ms, directed forgetting effect reversed significant, \\(M = -0.02\\), 95% CI \\([-0.07, 0.03]\\), \\(t(33) = -0.86\\), \\(p = .398\\). 1000ms, directed forgetting effect reversed significant, \\(M = -0.04\\), 95% CI \\([-0.09, 0.01]\\), \\(t(33) = -1.61\\), \\(p = .118\\). , 2000 ms, directed forgetting effect detected, \\(M = 0.01\\), 95% CI \\([-0.03, 0.06]\\), \\(t(33) = 0.47\\), \\(p = .643\\). encoding duration lure type interaction , \\(F(2, 66) = 2.99\\), \\(p = .057\\), \\(\\hat{\\eta}^2_G = .008\\), 90% CI \\([.000, .049]\\). 500 ms condition, proportion correct higher novel exemplar lures, \\(M = 0.23\\), 95% CI \\([0.19, 0.28]\\), \\(t(33) = 10.00\\), \\(p < .001\\). advantage novel exemplar items smaller 1000 ms condition, \\(M = 0.16\\), 95% CI \\([0.11, 0.21]\\), \\(t(33) = 6.80\\), \\(p < .001\\), 2000 ms condition \\(M = 0.21\\), 95% CI \\([0.16, 0.26]\\), \\(t(33) = 7.91\\), \\(p < .001\\). encoding instruction lure type interaction significant, \\(F(1, 33) = 1.24\\), \\(p = .273\\), \\(\\hat{\\eta}^2_G = .001\\), 90% CI \\([.000, .069]\\). Similarly, interaction encoding duration, instruction, lure type significant, \\(F(2, 66) = 0.01\\), \\(p = .988\\), \\(\\hat{\\eta}^2_G = .000\\), 90% CI \\([.000, .000]\\).","code":"## helper print functions qprint <- function(data,iv,level,dv){    data[[iv]] %>%    filter(.data[[iv]] == {level}) %>%    pull(dv) }  qprint_mean_sem <- function(data,iv,level,dv){    dv_mean <- data[[iv]] %>%    filter(.data[[iv]] == {level}) %>%    pull(dv[1])        dv_sem <- data[[iv]] %>%    filter(.data[[iv]] == {level}) %>%    pull(dv[2])        return(paste(\"M = \",      dv_mean,     \", SEM = \",     dv_sem,     sep=\"\"))     }  # qprint(Accuracy$means,\"encoding_stimulus_time\",\"500\",\"mean_correct\") # qprint_mean_sem(Accuracy$means,\"encoding_stimulus_time\",\"500\",c(\"mean_correct\",\"sem_correct\"))  # use data.table for interactions  #t <- as.data.table(Accuracy$means$`encoding_stimulus_time:encoding_instruction`) #t[encoding_stimulus_time==500 & encoding_instruction == \"F\"]$mean_correct"},{"path":[]},{"path":"/articles/E1_DF_Mixed.html","id":"conduct-analysis-1","dir":"Articles","previous_headings":"","what":"Conduct Analysis","title":"E1_DF_Mixed","text":"","code":"# create list to hold results RT <- list()  # Pre-process data for analysis # assign to \"filtered_data\" object RT$filtered_data <- all_data %>%   filter(experiment_phase == \"test\",           ID %in% all_excluded == FALSE,          rt != \"NULL\") %>%   mutate(rt = as.numeric(rt))  # declare factors, IVS, subject variable, and DV RT$factors$IVs <- c(\"encoding_stimulus_time\",                           \"encoding_instruction\",                           \"test_condition\") RT$factors$subject <- \"ID\" RT$factors$DV <- \"rt\"  ## Subject-level means used for ANOVA # get individual subject means for each condition RT$subject_means <- get_mean_sem(data=RT$filtered_data,                                        grouping_vars = c(RT$factors$subject,                                                          RT$factors$IVs),                                        dv = RT$factors$DV) ## Condition-level means # get all possible main effects and interactions RT$effects <- get_effect_names(RT$factors$IVs)  RT$means <- lapply(RT$effects, FUN = function(x) {   get_mean_sem(data=RT$filtered_data,              grouping_vars = x,              dv = RT$factors$DV) })  ## ANOVA  # ensure factors are factor class RT$subject_means <- RT$subject_means %>%   mutate_at(RT$factors$IVs,factor) %>%   mutate_at(RT$factors$subject,factor)  # run ANOVA RT$aov.out <- aov(mean_rt ~ encoding_stimulus_time*encoding_instruction*test_condition + Error(ID/(encoding_stimulus_time*encoding_instruction*test_condition)), RT$subject_means)  # save printable summaries RT$apa_print <- papaja::apa_print(RT$aov.out)"},{"path":"/articles/E1_DF_Mixed.html","id":"graphs-1","dir":"Articles","previous_headings":"","what":"Graphs","title":"E1_DF_Mixed","text":"","code":"RT$graphs$figure <- ggplot(RT$means$`encoding_stimulus_time:encoding_instruction:test_condition`,                                   aes(x=test_condition,                                      y=mean_rt,                                      group=encoding_instruction,                                      fill=encoding_instruction))+   geom_bar(stat=\"identity\", position=\"dodge\")+   geom_errorbar(aes(ymin = mean_rt-sem_rt,                     ymax = mean_rt+sem_rt),                 width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+   facet_wrap(~encoding_stimulus_time)+   coord_cartesian(ylim=c(1000,2000))+   scale_y_continuous(breaks = seq(1000,2000,100))+   theme_classic(base_size=12)+   ylab(\"Mean RT (ms)\")+   xlab(\"Lure Type\")+   scale_fill_discrete(name = \" Encoding \\n Instruction\") +   ggtitle(\"E1: Mean RT by Stimulus Encoding Duration, \\n Encoding Instruction, and Lure Type\")  RT$graphs$figure"},{"path":"/articles/E1_DF_Mixed.html","id":"print-anova-1","dir":"Articles","previous_headings":"","what":"Print ANOVA","title":"E1_DF_Mixed","text":"","code":"knitr::kable(xtable(summary(RT$aov.out)))"},{"path":"/articles/E1_DF_Mixed.html","id":"print-means-1","dir":"Articles","previous_headings":"","what":"Print Means","title":"E1_DF_Mixed","text":"","code":"print_list_of_tables(RT$means)"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/articles/E1_DF_Mixed.html","id":"comparisons-1","dir":"Articles","previous_headings":"","what":"Comparisons","title":"E1_DF_Mixed","text":"","code":"## Encoding time x instruction RT$simple$DF_500 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_rt) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$DF_1000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_rt) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$DF_2000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_rt) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  # encoding time x test condition  RT$simple$test_500 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,test_condition) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_rt) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$test_1000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_rt) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$test_2000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_rt) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()"},{"path":"/articles/E1_DF_Mixed.html","id":"write-up-1","dir":"Articles","previous_headings":"","what":"Write-up","title":"E1_DF_Mixed","text":"Mean reaction times correct trials subject condition submitted 3 (Encoding Duration: 500ms, 1000ms, 2000ms) x 2 (Encoding Instruction: Forget vs. Remember) x 2 (Lure type: Novel vs. Exemplar) fully repeated measures ANOVA. brevity report significant effects. full analysis contained supplementary materials. main effect encoding instruction significant, \\(F(1, 33) = 5.44\\), \\(p = .026\\), \\(\\hat{\\eta}^2_G = .003\\), 90% CI \\([.000, .092]\\). Mean reaction times faster choosing remember cued items (M = 1625.191, SEM = 13.987) forget cued items (M = 1662.582, SEM = 15.328). main effect lure type significant, \\(F(1, 33) = 6.74\\), \\(p = .014\\), \\(\\hat{\\eta}^2_G = .011\\), 90% CI \\([.000, .130]\\). Mean reaction times faster novel lure condition (M = 1603.181, SEM = 14.07) exemplar lure condition (M = 1684.996, SEM = 15.225). remaining main effects interactions significant.","code":""},{"path":"/articles/E1_DF_Mixed.html","id":"save-environment","dir":"Articles","previous_headings":"","what":"save environment","title":"E1_DF_Mixed","text":"","code":"save.image(\"data/E1/E1_data_write_up.RData\")"},{"path":"/articles/E2_DF_Blocked.html","id":"load-libraries","dir":"Articles","previous_headings":"","what":"Load libraries","title":"E2_DF_Blocked","text":"","code":"library(pacman) library(dplyr) library(tidyverse) library(jsonlite) library(xtable) library(data.table)"},{"path":"/articles/E2_DF_Blocked.html","id":"import-data","dir":"Articles","previous_headings":"","what":"Import Data","title":"E2_DF_Blocked","text":"","code":"# Read the text file from JATOS ... read_file('data/E2/jatos_results_20220329195903.txt') %>%   # ... split it into lines ...   str_split('\\n') %>% first() %>%   # ... filter empty rows ...   discard(function(x) x == '') %>%   # ... parse JSON into a data.frame   map_dfr(fromJSON, flatten=T) -> all_data"},{"path":"/articles/E2_DF_Blocked.html","id":"demographics","dir":"Articles","previous_headings":"","what":"Demographics","title":"E2_DF_Blocked","text":"total 45 participants recruited Amazon’s Mechanical Turk. Mean age 37.9 (range = 25 65 ). 11 females, 34 males. 42 right-handed participants, NA left handed participants. 36 participants reported normal vision, 8 participants reported corrected--normal vision. 41 participants reported English first language, 4 participants reported English second language.","code":"library(tidyr)  demographics <- all_data %>%   filter(trial_type == \"survey-html-form\") %>%   select(ID,response) %>%   unnest_wider(response) %>%   mutate(age = as.numeric(age))  age_demographics <- demographics %>%   summarize(mean_age = mean(age),             sd_age = sd(age),             min_age = min(age),             max_age = max(age))  factor_demographics <- apply(demographics[-1], 2, table)"},{"path":"/articles/E2_DF_Blocked.html","id":"pre-processing","dir":"Articles","previous_headings":"","what":"Pre-processing","title":"E2_DF_Blocked","text":"interested including participants attempted perform task best ability. adopted following exclusion criteria. Lower 75% correct encoding task. means participants failed correctly press F R keys trial.  25% Null responses (120*.25 = 30) test. NULL responses mean participant respond test trial 10 seconds.  Higher 75% response bias recognition task. suggests participants simply pressing button trials.  Making responses fast recognition memory test, indicating weren’t performing task. excluded participants whose mean RT less 300 ms.  Subjects included perform better 55% correct novel lures.","code":"# select data from the study phase study_accuracy <- all_data %>%   filter(experiment_phase == \"study\",          is.na(correct) == FALSE) %>%   group_by(ID)%>%   summarize(mean_correct = mean(correct))  study_excluded_subjects <- study_accuracy %>%   filter(mean_correct < .75) %>%   pull(ID)  ggplot(study_accuracy, aes(x=mean_correct))+   coord_cartesian(xlim=c(0,1))+   geom_vline(xintercept=.75)+   geom_histogram()+   ggtitle(\"Histogram of mean correct responses \\n for each subject during study phase\") # select data from the study phase test_null <- all_data %>%   filter(experiment_phase == \"test\",          response ==\"NULL\") %>%   group_by(ID) %>%   count()  test_null_excluded <- test_null %>%   filter(n > (120*.25)) %>%   pull(ID)  ggplot(test_null, aes(x=n))+   geom_vline(xintercept=30)+   geom_histogram()+   ggtitle(\"Histogram of count of null responses \\n for each subject during test\") test_response_bias <- all_data %>%   filter(experiment_phase == \"test\",          response !=\"NULL\") %>%   mutate(response = as.numeric(response)) %>%   group_by(ID, response) %>%   count() %>%   pivot_wider(names_from = response,               values_from = n,               values_fill = 0) %>%   mutate(bias = abs(`0` - `1`)/120)  test_response_bias_excluded <- test_response_bias %>%   filter(bias > .75) %>%   pull(ID)  ggplot(test_response_bias, aes(x=bias))+   geom_vline(xintercept=.75)+   geom_histogram()+   ggtitle(\"Histogram of response bias \\n for each subject during test phase\") test_mean_rt <- all_data %>%   filter(experiment_phase == \"test\",          response !=\"NULL\",          rt != \"NULL\") %>%   mutate(rt = as.numeric(rt)) %>%   group_by(ID) %>%   summarize(mean_RT = mean(rt))  test_mean_rt_excluded <- test_mean_rt %>%   filter(mean_RT < 300) %>%   pull(ID)  ggplot(test_mean_rt, aes(x=mean_RT))+   geom_vline(xintercept=300)+   geom_histogram()+   ggtitle(\"Histogram of response bias \\n for each subject during test phase\") test_mean_novel_accuracy <- all_data %>%   filter(experiment_phase == \"test\",          test_condition == \"novel\") %>%   mutate(correct = as.logical(correct)) %>%   group_by(ID) %>%   summarize(mean_correct = mean(correct))  test_mean_novel_accuracy_excluded <- test_mean_novel_accuracy %>%   filter(mean_correct < .4) %>%   pull(ID)  ggplot(test_mean_novel_accuracy, aes(x=mean_correct))+   geom_vline(xintercept=.4)+   geom_histogram()+   ggtitle(\"Histogram of mean accuracy for novel lures \\n for each subject during test phase\")"},{"path":"/articles/E2_DF_Blocked.html","id":"all-exclusions","dir":"Articles","previous_headings":"","what":"All exclusions","title":"E2_DF_Blocked","text":"participants recruited online completed experiment web browser. experiment script requests participants attempt task best ability. Nevertheless, possible participants complete experiment submit data without attempting complete task directed. developed set criteria exclude participants whose performance indicated attempting task instructed. criteria also allowed us confirm participants included analysis attempt task instructed best ability. adopted following five criteria: First, encoding phase participants responded instructional cue (remember forget picture trial) pressing “R” “F” keyboard. task demand served attentional check. excluded participants scored lower 75% correct instructional cue identification responses. Second, participants respond 25% trials recognition test excluded. Third, measured response bias (choosing left right picture) recognition test, excluded participants made 75% responses one side (indicating repeatedly pressing button trial). Fourth, excluded participants whose mean reaction time recognition test less 300ms, indicating pressing buttons fast possible without making recognition decision. Finally, computed mean accuracy novel lure condition participants, excluded participants whose mean accuracy less 55% items. together 6 participants excluded.","code":"all_excluded <- unique(c(study_excluded_subjects,                   test_null_excluded,                   test_response_bias_excluded,                   test_mean_rt_excluded,                   test_mean_novel_accuracy_excluded))  length(all_excluded) ## [1] 6"},{"path":[]},{"path":"/articles/E2_DF_Blocked.html","id":"define-helper-functions","dir":"Articles","previous_headings":"","what":"Define Helper functions","title":"E2_DF_Blocked","text":", consider moving functions R package project","code":"# attempt general solution  ## Declare helper functions  ################ # get_mean_sem # data = a data frame # grouping_vars = a character vector of factors for analysis contained in data # dv = a string indicated the dependent variable colunmn name in data # returns data frame with grouping variables, and mean_{dv}, sem_{dv} # note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv  get_mean_sem <- function(data, grouping_vars, dv, digits=3){   a <- data %>%     group_by_at(grouping_vars) %>%     summarize(\"mean_{ dv }\" := round(mean(.data[[dv]]), digits),               \"sem_{ dv }\" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),               .groups=\"drop\")   return(a) }  ################ # get_effect_names # grouping_vars = a character vector of factors for analysis # returns a named list # list contains all main effects and interaction terms # useful for iterating the computation means across design effects and interactions  get_effect_names <- function(grouping_vars){   effect_names <- grouping_vars   if( length(grouping_vars > 1) ){     for( i in 2:length(grouping_vars) ){       effect_names <- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=\":\"))     }   }   effects <- strsplit(effect_names, split=\":\")   names(effects) <- effect_names   return(effects) }  ################ # print_list_of_tables # table_list = a list of named tables # each table is printed  # names are header level 3  print_list_of_tables <- function(table_list){   for(i in 1:length(table_list)){     cat(\"###\",names(table_list[i]))     cat(\"\\n\")     print(knitr::kable(table_list[[i]]))     cat(\"\\n\")   } }"},{"path":"/articles/E2_DF_Blocked.html","id":"conduct-analysis","dir":"Articles","previous_headings":"","what":"Conduct Analysis","title":"E2_DF_Blocked","text":"","code":"# create list to hold results Accuracy <- list()  # Pre-process data for analysis # assign to \"filtered_data\" object Accuracy$filtered_data <- all_data %>%   filter(experiment_phase == \"test\",           ID %in% all_excluded == FALSE)  # declare factors, IVS, subject variable, and DV Accuracy$factors$IVs <- c(\"encoding_stimulus_time\",                           \"encoding_instruction\",                           \"test_condition\") Accuracy$factors$subject <- \"ID\" Accuracy$factors$DV <- \"correct\"  ## Subject-level means used for ANOVA # get individual subject means for each condition Accuracy$subject_means <- get_mean_sem(data=Accuracy$filtered_data,                                        grouping_vars = c(Accuracy$factors$subject,                                                          Accuracy$factors$IVs),                                        dv = Accuracy$factors$DV) ## Condition-level means # get all possible main effects and interactions Accuracy$effects <- get_effect_names(Accuracy$factors$IVs)  Accuracy$means <- lapply(Accuracy$effects, FUN = function(x) {   get_mean_sem(data=Accuracy$filtered_data,              grouping_vars = x,              dv = Accuracy$factors$DV) })  ## ANOVA  # ensure factors are factor class Accuracy$subject_means <- Accuracy$subject_means %>%   mutate_at(Accuracy$factors$IVs,factor) %>%   mutate_at(Accuracy$factors$subject,factor)  # run ANOVA Accuracy$aov.out <- aov(mean_correct ~ encoding_stimulus_time*encoding_instruction*test_condition + Error(ID/(encoding_stimulus_time*encoding_instruction*test_condition)), Accuracy$subject_means)  # save printable summaries Accuracy$apa_print <- papaja::apa_print(Accuracy$aov.out)"},{"path":"/articles/E2_DF_Blocked.html","id":"graphs","dir":"Articles","previous_headings":"","what":"Graphs","title":"E2_DF_Blocked","text":"","code":"Accuracy$graphs$figure <- ggplot(Accuracy$means$`encoding_stimulus_time:encoding_instruction:test_condition`,                                   aes(x=test_condition,                                      y=mean_correct,                                      group=encoding_instruction,                                      fill=encoding_instruction))+   geom_bar(stat=\"identity\", position=\"dodge\")+   geom_errorbar(aes(ymin = mean_correct-sem_correct,                     ymax = mean_correct+sem_correct),                 width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+   facet_wrap(~encoding_stimulus_time)+   coord_cartesian(ylim=c(.4,1))+   geom_hline(yintercept=.5)+   scale_y_continuous(breaks = seq(0.4,1,.1))+   theme_classic(base_size=12)+   ylab(\"Proportion Correct\")+   xlab(\"Lure Type\")+   scale_fill_discrete(name = \" Encoding \\n Instruction\") +   ggtitle(\"E2: Proportion Correct by Stimulus Encoding Duration, \\n Encoding Instruction, and Lure Type\")  Accuracy$graphs$figure"},{"path":"/articles/E2_DF_Blocked.html","id":"print-anova","dir":"Articles","previous_headings":"","what":"Print ANOVA","title":"E2_DF_Blocked","text":"","code":"knitr::kable(xtable(summary(Accuracy$aov.out)))"},{"path":"/articles/E2_DF_Blocked.html","id":"print-means","dir":"Articles","previous_headings":"","what":"Print Means","title":"E2_DF_Blocked","text":"","code":"print_list_of_tables(Accuracy$means)"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/articles/E2_DF_Blocked.html","id":"comparisons","dir":"Articles","previous_headings":"","what":"Comparisons","title":"E2_DF_Blocked","text":"","code":"## Encoding time x instruction Accuracy$simple$DF_500 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_correct) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$DF_1000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_correct) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$DF_2000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_correct) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  # encoding time x test condition  Accuracy$simple$test_500 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,test_condition) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_correct) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$test_1000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_correct) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  Accuracy$simple$test_2000 <- Accuracy$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_correct = mean(mean_correct)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_correct) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()"},{"path":"/articles/E2_DF_Blocked.html","id":"write-up","dir":"Articles","previous_headings":"","what":"Write-up","title":"E2_DF_Blocked","text":"Proportion correct subject condition submitted 3 (Encoding Duration: 500ms, 1000ms, 2000ms) x 2 (Encoding Instruction: Forget vs. Remember) x 2 (Lure type: Novel vs. Exemplar) fully repeated measures ANOVA. completeness, main effect higher-order interaction described turn. main effect encoding duration significant, \\(F(2, 76) = 5.54\\), \\(p = .006\\), \\(\\hat{\\eta}^2_G = .017\\), 90% CI \\([.000, .074]\\). Proportion correct lowest 500 ms duration (M = 0.61, SEM = 0.012), higher 1000 ms (M = 0.632, SEM = 0.012), 2000 ms (M = 0.667, SEM = 0.012) stimulus durations. main effect encoding instruction significant, \\(F(1, 38) = 0.65\\), \\(p = .425\\), \\(\\hat{\\eta}^2_G = .001\\), 90% CI \\([.000, .055]\\). Proportion correct similar remember cues (M = 0.642, SEM = 0.01) forget cues (M = 0.631, SEM = 0.01). main effect lure type significant, \\(F(1, 38) = 79.66\\), \\(p < .001\\), \\(\\hat{\\eta}^2_G = .137\\), 90% CI \\([.014, .312]\\). Proportion correct higher novel lures (M = 0.709, SEM = 0.009) exemplar lures (M = 0.564, SEM = 0.01). main question interest whether directing forgetting vary across encoding duration times. interaction encoding instruction encoding duration significant, \\(F(2, 76) = 0.83\\), \\(p = .441\\), \\(\\hat{\\eta}^2_G = .002\\), 90% CI \\([.000, .013]\\). Paired sample t-tests used assess directed forgetting effect encoding duration. directed forgetting effect taken difference proportion correct remember minus forget items. 500 ms, directed forgetting effect significant, \\(M = 0.03\\), 95% CI \\([-0.01, 0.07]\\), \\(t(38) = 1.36\\), \\(p = .181\\). 1000ms, directed forgetting effect significant, \\(M = 0.02\\), 95% CI \\([-0.03, 0.06]\\), \\(t(38) = 0.63\\), \\(p = .531\\). , 2000 ms, directed forgetting effect detected, \\(M = -0.01\\), 95% CI \\([-0.06, 0.04]\\), \\(t(38) = -0.49\\), \\(p = .629\\). encoding duration lure type interaction significnat, \\(F(2, 76) = 0.26\\), \\(p = .775\\), \\(\\hat{\\eta}^2_G = .001\\), 90% CI \\([.000, .000]\\). encoding instruction lure type interaction significant, \\(F(1, 38) = 1.13\\), \\(p = .295\\), \\(\\hat{\\eta}^2_G = .001\\), 90% CI \\([.000, .065]\\). Similarly, interaction encoding duration, instruction, lure type significant, \\(F(2, 76) = 2.42\\), \\(p = .095\\), \\(\\hat{\\eta}^2_G = .005\\), 90% CI \\([.000, .037]\\).","code":"## helper print functions qprint <- function(data,iv,level,dv){    data[[iv]] %>%    filter(.data[[iv]] == {level}) %>%    pull(dv) }  qprint_mean_sem <- function(data,iv,level,dv){    dv_mean <- data[[iv]] %>%    filter(.data[[iv]] == {level}) %>%    pull(dv[1])        dv_sem <- data[[iv]] %>%    filter(.data[[iv]] == {level}) %>%    pull(dv[2])        return(paste(\"M = \",      dv_mean,     \", SEM = \",     dv_sem,     sep=\"\"))     }  # qprint(Accuracy$means,\"encoding_stimulus_time\",\"500\",\"mean_correct\") # qprint_mean_sem(Accuracy$means,\"encoding_stimulus_time\",\"500\",c(\"mean_correct\",\"sem_correct\"))  # use data.table for interactions  #t <- as.data.table(Accuracy$means$`encoding_stimulus_time:encoding_instruction`) #t[encoding_stimulus_time==500 & encoding_instruction == \"F\"]$mean_correct"},{"path":[]},{"path":"/articles/E2_DF_Blocked.html","id":"conduct-analysis-1","dir":"Articles","previous_headings":"","what":"Conduct Analysis","title":"E2_DF_Blocked","text":"","code":"# create list to hold results RT <- list()  # Pre-process data for analysis # assign to \"filtered_data\" object RT$filtered_data <- all_data %>%   filter(experiment_phase == \"test\",           ID %in% all_excluded == FALSE,          rt != \"NULL\") %>%   mutate(rt = as.numeric(rt))  # declare factors, IVS, subject variable, and DV RT$factors$IVs <- c(\"encoding_stimulus_time\",                           \"encoding_instruction\",                           \"test_condition\") RT$factors$subject <- \"ID\" RT$factors$DV <- \"rt\"  ## Subject-level means used for ANOVA # get individual subject means for each condition RT$subject_means <- get_mean_sem(data=RT$filtered_data,                                        grouping_vars = c(RT$factors$subject,                                                          RT$factors$IVs),                                        dv = RT$factors$DV) ## Condition-level means # get all possible main effects and interactions RT$effects <- get_effect_names(RT$factors$IVs)  RT$means <- lapply(RT$effects, FUN = function(x) {   get_mean_sem(data=RT$filtered_data,              grouping_vars = x,              dv = RT$factors$DV) })  ## ANOVA  # ensure factors are factor class RT$subject_means <- RT$subject_means %>%   mutate_at(RT$factors$IVs,factor) %>%   mutate_at(RT$factors$subject,factor)  # run ANOVA RT$aov.out <- aov(mean_rt ~ encoding_stimulus_time*encoding_instruction*test_condition + Error(ID/(encoding_stimulus_time*encoding_instruction*test_condition)), RT$subject_means)  # save printable summaries RT$apa_print <- papaja::apa_print(RT$aov.out)"},{"path":"/articles/E2_DF_Blocked.html","id":"graphs-1","dir":"Articles","previous_headings":"","what":"Graphs","title":"E2_DF_Blocked","text":"","code":"RT$graphs$figure <- ggplot(RT$means$`encoding_stimulus_time:encoding_instruction:test_condition`,                                   aes(x=test_condition,                                      y=mean_rt,                                      group=encoding_instruction,                                      fill=encoding_instruction))+   geom_bar(stat=\"identity\", position=\"dodge\")+   geom_errorbar(aes(ymin = mean_rt-sem_rt,                     ymax = mean_rt+sem_rt),                 width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+   facet_wrap(~encoding_stimulus_time)+   coord_cartesian(ylim=c(1000,2000))+   scale_y_continuous(breaks = seq(1000,2000,100))+   theme_classic(base_size=12)+   ylab(\"Mean RT (ms)\")+   xlab(\"Lure Type\")+   scale_fill_discrete(name = \" Encoding \\n Instruction\") +   ggtitle(\"E2: Mean RT by Stimulus Encoding Duration, \\n Encoding Instruction, and Lure Type\")  RT$graphs$figure"},{"path":"/articles/E2_DF_Blocked.html","id":"print-anova-1","dir":"Articles","previous_headings":"","what":"Print ANOVA","title":"E2_DF_Blocked","text":"","code":"knitr::kable(xtable(summary(RT$aov.out)))"},{"path":"/articles/E2_DF_Blocked.html","id":"print-means-1","dir":"Articles","previous_headings":"","what":"Print Means","title":"E2_DF_Blocked","text":"","code":"print_list_of_tables(RT$means)"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"/articles/E2_DF_Blocked.html","id":"comparisons-1","dir":"Articles","previous_headings":"","what":"Comparisons","title":"E2_DF_Blocked","text":"","code":"## Encoding time x instruction RT$simple$DF_500 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_rt) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$DF_1000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_rt) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$DF_2000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,encoding_instruction) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = encoding_instruction,               values_from = mean_rt) %>%   mutate(difference = R-F) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  # encoding time x test condition  RT$simple$test_500 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"500\") %>%   group_by(ID,test_condition) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_rt) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$test_1000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"1000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_rt) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()  RT$simple$test_2000 <- RT$subject_means %>%   filter(encoding_stimulus_time == \"2000\") %>%   group_by(ID,test_condition) %>%   summarize(mean_rt = mean(mean_rt)) %>%   pivot_wider(names_from = test_condition,               values_from = mean_rt) %>%   mutate(difference = novel-exemplar) %>%   pull(difference) %>%   t.test() %>%   papaja::apa_print()"},{"path":"/articles/E2_DF_Blocked.html","id":"write-up-1","dir":"Articles","previous_headings":"","what":"Write-up","title":"E2_DF_Blocked","text":"Mean reaction times correct trials subject condition submitted 3 (Encoding Duration: 500ms, 1000ms, 2000ms) x 2 (Encoding Instruction: Forget vs. Remember) x 2 (Lure type: Novel vs. Exemplar) fully repeated measures ANOVA. brevity report significant effects. full analysis contained supplementary materials. main effect lure type significant, \\(F(1, 38) = 7.32\\), \\(p = .010\\), \\(\\hat{\\eta}^2_G = .014\\), 90% CI \\([.000, .128]\\). Mean reaction times faster novel lure condition (M = 1644.224, SEM = 13.401) exemplar lure condition (M = 1741.122, SEM = 15.939). remaining main effects interactions significant.","code":""},{"path":"/articles/E2_DF_Blocked.html","id":"save-environment","dir":"Articles","previous_headings":"","what":"save environment","title":"E2_DF_Blocked","text":"","code":"save.image(\"data/E2/E2_data_write_up.RData\")"},{"path":"/articles/Experiments.html","id":"experiment-1-mixed-stimulus-duration","dir":"Articles","previous_headings":"","what":"Experiment 1: Mixed stimulus duration","title":"Experiments","text":"Estimated time: 15-20 minutes directed forgetting task pictures natural scenes. shown many pictures asked remember forget picture. given memory test. First Time? Click link participate experiment Try Experiment () Trying ? interested data first-time attempts, please click first link (can ). , want try , go : Try Experiment ","code":""},{"path":"/articles/Experiments.html","id":"experiment-2-blocked-stimulus-duration","dir":"Articles","previous_headings":"","what":"Experiment 2: Blocked stimulus duration","title":"Experiments","text":"Estimated time: 15-20 minutes directed forgetting task pictures natural scenes. shown many pictures asked remember forget picture. given memory test. First Time? Click link participate experiment Try Experiment () Trying ? interested data first-time attempts, please click first link (can ). , want try , go : Try Experiment ","code":""},{"path":"/articles/power_analysis.html","id":"set-predictions","dir":"Articles","previous_headings":"","what":"Set predictions","title":"power_analysis","text":"replicated Experiment 1 Ahmad, Tan, Hockley (2019), addition stimulus duration manipulation. original study presented pictures 2000ms encoding phase. presented pictures 500ms, 1000ms, 2000ms encoding phase. assumed reducing encoding generally reduce memorability pictures. programmed main effect stimulus duration prediction vector, assumed proportion correct decrease 5% shorter duration. also assumed directed forgetting easier less memorable stimuli, increased directed forgetting effect exemplar lures 5% shorter duration. also programmed advantage novel exemplar lures.","code":"library(tidyverse)  # save results to this list power_analysis <- list()  # predictions for mean accuracy in each condition (see paper for rationale) power_analysis$predictions = c(.90-.1, #R 500 Novel                 .80-.1, #R 500 Exemplar                 .90-.05, #R 1000 Novel                 .80-.05, #R 1000 Exemplar                 .90, #R 2000 Novel                 .80, #R 2000 Exemplar                 .90-.1, #F 500 Novel                 .70-.1-.1, #F 500 Exemplar                 .90-.05, #F 1000 Novel                 .70-.05-.05, #F 1000 Exemplar                 .90, #F 2000 Novel                 .70 #F 2000 Exemplar )"},{"path":"/articles/power_analysis.html","id":"graph-predictions","dir":"Articles","previous_headings":"","what":"Graph Predictions","title":"power_analysis","text":"","code":"# graph power_analysis$predicted_means <- data.frame(   encoding_cue = rep(c(\"R\",\"F\"), each = 6),   image_duration = rep(rep(c(.5,1,2), each = 2),2),   test_condition = rep(rep(c(\"Novel\",\"Exemplar\"),each = 1),6),   accuracy = power_analysis$predictions )  power_analysis$prediction_graph <- ggplot(   power_analysis$predicted_means,   aes(x=test_condition,y = accuracy, fill=encoding_cue))+   geom_bar(stat=\"identity\", position=\"dodge\")+   geom_hline(yintercept=.5)+   coord_cartesian(ylim=c(.4,1))+   scale_y_continuous(breaks = seq(0.4,1,.1))+   facet_wrap(~image_duration)+   ylab(\"Proportion Correct\")+   xlab(\"Lure Type\")+   scale_fill_discrete(name = \" Encoding \\n Instruction\") +   ggtitle(\"Predictions for mean accuracy \\n as a function of Stimulus Duration, \\n Encoding Instruction, and Lure Type\")  power_analysis$prediction_graph # function to generate simulated data for one subject # we use the binomial to generate decisions for old/new on each trial # the binomial probability of success is set to the mean accuracy for each condition # we simulate all 120 trials for a single simulated subject. create_n_subjects <- function(n){      all_data <- data.frame()   for(i in 1:n){     subject_data <- data.frame(       sub_num = i,       encoding_cue = rep(c(\"R\",\"F\"), each = 60),       image_duration = rep(rep(c(.5,1,2), each = 20),2),       test_condition = rep(rep(c(\"Novel\",\"Exemplar\"),each = 10),6),       accuracy = rbinom(120,1,rep(power_analysis$predictions,each=10))       )          all_data <- rbind(all_data,subject_data)   }      return(all_data)    }"},{"path":"/articles/power_analysis.html","id":"run-simulation","dir":"Articles","previous_headings":"","what":"Run simulation","title":"power_analysis","text":"run simulation power design detect effects interest n = 35.","code":"power_analysis$all_sim_data <- data.frame() num_subs <- 35 num_sims <- 100 for(i in 1:num_sims){   #print(i)   simulated_data <- create_n_subjects(n=num_subs)      # ensure factors are factor class   simulated_data <- simulated_data %>%     mutate_at(c(\"sub_num\",\"encoding_cue\",\"image_duration\",\"test_condition\"), factor)       ANOVA_means <- simulated_data %>%     group_by(sub_num,encoding_cue,image_duration,test_condition) %>%     summarize(mean_accuracy =  mean(accuracy), .groups=\"drop\")      sim_anova <- aov(mean_accuracy ~ encoding_cue*image_duration*test_condition + Error(sub_num/(encoding_cue*image_duration*test_condition)), data = ANOVA_means)   save_summary <- summary(sim_anova)      cue <- save_summary$`Error: sub_num:encoding_cue`[[1]]$`Pr(>F)`[1]   cue_duration <- save_summary$`Error: sub_num:encoding_cue:image_duration`[[1]]$`Pr(>F)`[1]   cue_test <- save_summary$`Error: sub_num:encoding_cue:test_condition`[[1]]$`Pr(>F)`[1]   cue_duration_test <- save_summary$`Error: sub_num:encoding_cue:image_duration:test_condition`[[1]]$`Pr(>F)`[1]      t_df <- data.frame(cue,                      cue_duration,                      cue_test,                      cue_duration_test)   power_analysis$all_sim_data <- rbind(power_analysis$all_sim_data,t_df) }   proportion_sig <- function(ps){   length(ps[ps<.05])/length(ps) }   # proportion significant for relevant effects power_analysis$sim_power <- apply(power_analysis$all_sim_data,2,proportion_sig) power_analysis$sim_power #>               cue      cue_duration          cue_test cue_duration_test  #>              1.00              0.21              1.00              0.23"},{"path":"/articles/power_analysis.html","id":"save-out","dir":"Articles","previous_headings":"","what":"save out","title":"power_analysis","text":"","code":"save.image(\"data/power.RData\")"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Patrick Ihejirika. Author. Matthew J. C. Crump. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ihejirika P, Crump M (2022). ForgettingPictures: vertical repository Patrick Ihejirika's honor's thesis project. R package version 0.0.0.9000.","code":"@Manual{,   title = {ForgettingPictures: A vertical repository for Patrick Ihejirika's honor's thesis project},   author = {Patrick Ihejirika and Matthew J. C. Crump},   year = {2022},   note = {R package version 0.0.0.9000}, }"},{"path":[]},{"path":"/index.html","id":"try-and-forget-this-image-the-role-of-stimulus-duration-in-directed-forgetting-for-natural-scenes","dir":"","previous_headings":"","what":"Try and forget this image: The role of stimulus duration in directed forgetting for natural scenes","title":"A vertical repository for Patrick Ihejirikas honors thesis project","text":"Author: Patrick Ihejirika | Advisor: Matt Crump Undergraduate Honor’s Thesis submitted partial fulfillment requirements graduating Departmental Honors Psychology. NOTE: project currently development completed Spring 2022","code":""},{"path":"/index.html","id":"abstract","dir":"","previous_headings":"","what":"Abstract","title":"A vertical repository for Patrick Ihejirikas honors thesis project","text":"useful selectively forget events choose forget? Directed forgetting research tool used investigate limitations deliberate forgetting abilities. directed forgetting task people encode individual items instructed (cued) either remember forget . directed forgetting effect observed performance memory test higher remember-cued items forget-cued items. Directed forgetting effects reproduced numerous times, commonly demonstrated tasks using lists words items remembered forgotten (Epstein, 1969). Much less known directed forgetting memorable stimuli like images, pictures, visual scenes. Ahmad, Tan & Hockley showed weak directed forgetting effect can fact observed image stimuli (2019). honors thesis project investigates general memory strength hypothesis directed forgetting pictures. According hypothesis, pictures difficult intentionally forget encoded well attempts forget information ineffective. propose weakening encoding strength images allow intentional forgetting processes operate effectively, causing increased directed forgetting effect. experiments used general procedures Ahmad, Tan, Hockley (2019). two experiments (n=45 ), reduced encoding strength manipulating stimulus duration encoding (2000 ms [original amount], 1000ms, 500 ms per picture). predicted greater directed forgetting observed stimulus duration decreased. discuss results two experiments relation general memory strength hypothesis.","code":""},{"path":"/index.html","id":"project-information","dir":"","previous_headings":"","what":"Project Information","title":"A vertical repository for Patrick Ihejirikas honors thesis project","text":"goal {ForgettingPictures} share Patrick Ihejirika’s honor thesis project reproducible vertical project. purpose thesis determine whether directed forgetting pictures influenced changes decreases encoding time (stimulus duration) pictures presented encoding phase recognition memory task. honor’s thesis available pdf form manuscript tab. supplementary materials tab contains power analysis, results two experiments. theory entire project shared computationally reproducible format. github repository website contains source code generating thesis, original data, data analysis, experiment scripts used run experiment.","code":""}]
